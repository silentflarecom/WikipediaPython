# Term Corpus Generator

A lightweight, full-stack web application designed to generate bilingual (English & Chinese) corpus data for economic and general terms. Built with **FastAPI** and **Vue 3**.

![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Python](https://img.shields.io/badge/python-3.9+-blue.svg)
![Vue](https://img.shields.io/badge/vue-3.x-green.svg)

## ğŸš€ Features

- **Instant Bilingual Search**: Input a term (e.g., "Inflation") and retrieve its summary in both English and Chinese simultaneously.
- **Wikipedia Integration**: Automatically fetches data from Wikipedia using the `wikipedia-api` library, leveraging language links for accurate cross-lingual mapping.
- **Dual-View Interface**: Clean, modern UI displaying English and Chinese definitions side-by-side.
- **Auto-Save to Markdown**: Every search result is automatically saved as a Markdown file in the backend's `output/` directory.
- **JSON Export**: One-click export of current search results to a JSON file from the frontend.

### âš¡ New Features (v2.0)

- **ğŸ“š Batch Import & Automation**: Crawl hundreds of terms automatically via text input or file upload (CSV/TXT).
- **ğŸ‡¨ğŸ‡³ Smart Chinese Conversion**: Automatically converts Traditional Chinese (Wikipedia default) to Simplified Chinese using `zhconv`.
- **ğŸ“Š Real-time Monitoring**: Dashboard to track crawling progress, success/failure rates, and current status.
- **ğŸ’¾ Database Persistence**: Uses SQLite to store crawl history, allowing you to resume tasks or export data anytime.
- **ğŸ“¥ Robust Export**: Download results as valid JSON files or UTF-8 encoded CSVs (Excel compatible).

### ğŸŒ New Features (v2.1 - Intelligent Association Crawling)

- **ğŸ•¸ï¸ Knowledge Graph Visualization**: Interactive D3.js force-directed graph showing term relationships.
- **ğŸ¯ Depth-Controlled Crawling**: Configure crawl depth (1-3 levels) to automatically discover related terms from "See Also" and internal links.
- **ğŸ“Š Association Tracking**: Stores term relationships (links, categories) in database for graph generation.
- **ï¿½ï¸ Multi-Format Export**: Export knowledge graphs as PNG (high-res), SVG (editable), or JSON (data).
- **ğŸ¯ Smart Label Display**: Only shows labels for root and first-layer nodes to reduce visual clutter.

## ï¿½ğŸ› ï¸ Tech Stack

### Backend
- **FastAPI**: High-performance web framework.
- **SQLite + aiosqlite**: Async database for managing batch tasks.
- **Wikipedia-API**: Official MediaWiki API wrapper.
- **zhconv**: Advanced Traditional-to-Simplified Chinese conversion.
- **Pydantic**: Data validation.

### Frontend
- **Vue 3 + Vite**: Lightning fast frontend.
- **TailwindCSS**: Utility-first styling.
- **D3.js**: Knowledge graph visualization.
- **Axios**: HTTP client.

## âš–ï¸ Compliance & Best Practices

This tool is designed to strictly adhere to [Wikipedia's User-Agent Policy](https://meta.wikimedia.org/wiki/User-Agent_policy) and API Usage Guidelines:
 
1.  **Official API**: Uses the standard MediaWiki API endpoints, not screen scraping.
2.  **User-Agent**: Sends a strict, transparent header (`WikipediaTermCorpusGenerator/1.0 (Student Project; contact@silentflare.com)`) to identify the traffic source.
3.  **Rate Limiting**: Enforces a configurable delay (default 3s) between requests used in batch mode to prevent server overload.
4.  **Sequential Processing**: Batch tasks are processed serially to maintain a low concurrency footprint.

## ğŸ—ºï¸ Advanced Automation Roadmap

### ğŸ¯ Planned Features

#### **Phase 1: Batch Import & Automated Crawling** âœ… COMPLETED
- **Batch Input Methods**: 
  - Paste multiple terms (one per line) âœ…
  - Upload CSV/TXT files âœ…
- **Automation Controls**:
  - Concurrent crawling with rate limiting âœ…
  - Real-time progress monitoring âœ…
  - Automatic retry mechanism âœ…
- **Results Management**:
  - Batch export to JSON/CSV (Simplified Chinese support) âœ…
  - Database persistence âœ…

#### **Phase 2: Intelligent Association Crawling** âœ… COMPLETED
- **Link Discovery Strategies**:
  - "See also" sections from Wikipedia pages âœ…
  - High-frequency internal links (via Associations) âœ…
  - Category tags exploration âœ…
  - Cross-language related articles (via langlinks) âœ…
- **Crawl Depth Control**:
  - Configurable depth levels (1-3 layers) âœ…
  - Maximum terms per layer âœ…
  - Blacklist filtering for irrelevant terms (Basic filtering implemented) âœ…
- **Knowledge Graph Visualization**:
  - Force-directed graph of term relationships âœ…
  - Topic clustering display (via Force Layout) âœ…
  - **Multi-format export: PNG, SVG, JSON** âœ…
  - Smart full-graph capture (ignores zoom state) âœ…

#### **Phase 3: Corpus Quality & Data Management** ğŸ¯ IN PROGRESS
- **Term Deduplication**:
  - Detect duplicate terms before batch crawling
  - UI warning for existing terms with skip/force options
  - Global duplicate check across all tasks
- **Data Quality Control**:
  - Automatic quality analysis (missing translations, short summaries)
  - Quality report dashboard
  - Data cleaning tools (remove failed/low-quality entries)
- **Batch Task Management**:
  - View all historical batch tasks
  - Delete/archive old tasks
  - Merge multiple tasks into unified corpus

#### **Phase 4: Advanced Export & Persistence**
- **Multi-Format Export**:
  - JSONL (one JSON object per line) - ML training ready
  - TMX (Translation Memory eXchange) - CAT tool compatible
  - TSV (Tab-separated values) - Excel/Pandas friendly
  - TXT (Plain text bilingual pairs) - Simple readable format
  - Parquet (Optional) - Big data processing
- **Data Persistence**:
  - Database backup/restore functionality
  - Complete data reset with confirmation
  - Export entire corpus as portable file

#### **Phase 5: Corpus Statistics & Analytics**
- **Statistics Dashboard**:
  - Total terms / bilingual pairs count
  - Character count (EN/ZH separately)
  - Average summary length
  - Database size metrics
  - Knowledge graph node/edge counts
- **Coverage Analysis**:
  - Success rate visualization
  - Missing translation tracking
  - Domain distribution (if tagged)

### ğŸ—ï¸ Technical Architecture (Phase 1 Preview)

**Backend Enhancements**:
```
backend/
â”œâ”€â”€ main.py              # Existing FastAPI main file
â”œâ”€â”€ worker.py            # New: Background task worker (Celery/RQ)
â”œâ”€â”€ models.py            # New: Database models
â”œâ”€â”€ scheduler.py         # New: Batch crawl scheduler
â”œâ”€â”€ database.py          # New: Database connection
â””â”€â”€ utils/
    â”œâ”€â”€ rate_limiter.py  # Rate limiting control
    â””â”€â”€ retry.py         # Retry logic
```

**Frontend Enhancements**:
```
frontend/src/
â”œâ”€â”€ App.vue                    # Existing main component
â””â”€â”€ components/
    â”œâ”€â”€ BatchImport.vue        # Batch import interface
    â”œâ”€â”€ ProgressMonitor.vue    # Progress tracking
    â””â”€â”€ ResultsTable.vue       # Results data table
```

**Database Schema** (SQLite for Phase 1):
```sql
-- Batch tasks tracking
CREATE TABLE tasks (
    id INTEGER PRIMARY KEY,
    status TEXT,
    created_at TIMESTAMP,
    total_terms INTEGER,
    completed INTEGER
);

-- Individual terms
CREATE TABLE terms (
    id INTEGER PRIMARY KEY,
    task_id INTEGER,
    term TEXT,
    status TEXT,
    en_summary TEXT,
    zh_summary TEXT,
    created_at TIMESTAMP,
    updated_at TIMESTAMP
);
```

### ğŸ“ˆ Implementation Priority

1. **Immediate** (Phase 1): Batch crawling - 10x efficiency boost with minimal complexity
2. **Short-term** (Phases 2-3): Intelligent crawling and scheduling - transform into self-growing knowledge base
3. **Mid-term** (Phases 4-5): Multi-source and AI enhancement - professional-grade corpus quality
4. **Long-term** (Phase 6): Distributed architecture - only when corpus exceeds 10,000+ terms

---

*This roadmap reflects the evolution from a simple search tool to an enterprise-grade knowledge corpus management system.*
